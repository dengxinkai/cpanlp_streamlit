import streamlit as st
import numpy as np
import pandas as pd
import base64
import os
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain.llms import OpenAI
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma

result=""
if "prev_input_text" not in st.session_state:
    st.session_state.prev_input_text = ""
st.set_page_config(
    page_title="cpanlpçš„æœºå™¨å­¦ä¹ ",
    page_icon="ğŸ±",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': 'https://www.cpanlp.com/',
        'Report a bug': "https://www.cpanlp.com/",
        'About': "å¾ˆé«˜å…´æ‚¨ä½¿ç”¨cpanlpçš„æœºå™¨å­¦ä¹ é¡¹ç›®"
    }
)
st.write("[è¿”å›](https://cpanlp.com/example/)")
input_text = st.text_input('PDFç½‘å€', '')
input_text1 = st.text_input('æŸ¥è¯¢', '')

query = input_text1
result = None
do_query = False

import pickle

# åˆå§‹åŒ–prev_input_textå˜é‡
if "prev_input_text" not in st.session_state:
    st.session_state.prev_input_text = ""

# åŠ è½½æˆ–åˆ›å»ºqaå¯¹è±¡
if "qa" in st.session_state:
    qa = pickle.loads(st.session_state.qa)
else:
    # åˆå§‹åŒ–qaå¯¹è±¡
    loader = PyPDFLoader(input_text)
    documents = loader.load()
    text_splitter = RecursiveCharacterTextSplitter(
        # Set a really small chunk size, just to show.
        chunk_size=200,
        chunk_overlap=20,
        length_function=len,
    )
    texts = text_splitter.split_documents(documents)
    embeddings = OpenAIEmbeddings()
    db = Chroma.from_documents(texts, embeddings)
    retriever = db.as_retriever()
    qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type="stuff", retriever=retriever)

input_text = st.text_input('PDFç½‘å€', '')
input_text1 = st.text_input('æŸ¥è¯¢', '')

query = input_text1
result = None
do_query = False

if st.button('ç¡®è®¤'):
    if input_text != st.session_state.prev_input_text:
        # å¦‚æœinput_textå˜åŒ–äº†ï¼Œåˆ™é‡æ–°åŠ è½½æ–‡æ¡£å’ŒQAæ¨¡å‹
        loader = PyPDFLoader(input_text)
        documents = loader.load()
        text_splitter = RecursiveCharacterTextSplitter(
            # Set a really small chunk size, just to show.
            chunk_size=200,
            chunk_overlap=20,
            length_function=len,
        )
        texts = text_splitter.split_documents(documents)
        embeddings = OpenAIEmbeddings()
        db = Chroma.from_documents(texts, embeddings)
        retriever = db.as_retriever()
        qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type="stuff", retriever=retriever)
        
        # ä¿å­˜qaå¯¹è±¡åˆ°session stateä¸­
        st.session_state.qa = pickle.dumps(qa)
        
        # æ›´æ–°prev_input_textçš„å€¼
        st.session_state.prev_input_text = input_text
        # æ‰§è¡ŒæŸ¥è¯¢
        result = qa.run(query)
        do_query = True
    else:
        # å¦‚æœinput_textæ²¡æœ‰å˜åŒ–ï¼Œåˆ™åªæ‰§è¡ŒæŸ¥è¯¢
        result = qa.run(query)
        do_query = True

# è¾“å‡ºç»“æœ
if do_query:
    st.write(result)



uploaded_file = st.file_uploader("ä¸Šä¼ csvæ–‡ä»¶", type="csv")

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    st.success("csvå¯¼å…¥æˆdfæˆåŠŸ")
    st.write(df)


